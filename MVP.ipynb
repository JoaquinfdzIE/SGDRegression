{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea433205-bb5c-452b-8fea-59c0a056cc42",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8065/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x13dd07a50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pickle\n",
    "import dash\n",
    "from dash import dcc, html\n",
    "from dash.dependencies import Input, Output\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "# Load and prepare data\n",
    "def load_and_prepare_data(file_path):\n",
    "    data = pd.read_pickle(file_path)\n",
    "    \n",
    "    # Aggregate the data by product_id and day of the week\n",
    "    data_grouped = data.groupby(['product_id', 'day']).agg({\n",
    "        'purchase': 'sum',\n",
    "        'price': 'mean',\n",
    "        'week': 'mean',\n",
    "        'month': 'mean',\n",
    "        'year': 'mean',\n",
    "        'cart': 'mean',\n",
    "        'view': 'mean',\n",
    "        'category_num': 'mean'\n",
    "    }).reset_index()\n",
    "    \n",
    "    return data_grouped\n",
    "\n",
    "# Function to train the model incrementally\n",
    "def train_incremental_model(data_grouped, model=None, scaler=None):\n",
    "    X = data_grouped[['price', 'day', 'week', 'month', 'year', 'cart', 'view', 'category_num']]\n",
    "    y = data_grouped['purchase']\n",
    "    \n",
    "    if scaler is None:\n",
    "        scaler = StandardScaler()\n",
    "        X = scaler.fit_transform(X)\n",
    "    else:\n",
    "        X = scaler.transform(X)\n",
    "    \n",
    "    if model is None:\n",
    "        model = SGDRegressor(max_iter=1000, tol=1e-3)\n",
    "        model.partial_fit(X, y)\n",
    "    else:\n",
    "        model.partial_fit(X, y)\n",
    "    \n",
    "    return model, scaler\n",
    "\n",
    "# Load initial data and train the model\n",
    "file_path = 'forecasting_dataset.pkl'\n",
    "data_grouped = load_and_prepare_data(file_path)\n",
    "model, scaler = train_incremental_model(data_grouped)\n",
    "\n",
    "# Save the model and the scaler\n",
    "with open('model.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "with open('scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "# Get the list of unique product_ids for the dropdown\n",
    "product_ids = data_grouped['product_id'].unique()\n",
    "\n",
    "# Initialize the Dash app\n",
    "app = dash.Dash(__name__)\n",
    "\n",
    "# Define the layout of the app\n",
    "app.layout = html.Div([\n",
    "    html.H1(\"Sales Prediction\"),\n",
    "    html.Label(\"Product ID:\"),\n",
    "    dcc.Dropdown(\n",
    "        id='product_id',\n",
    "        options=[{'label': str(pid), 'value': pid} for pid in product_ids],\n",
    "        value=product_ids[0]\n",
    "    ),\n",
    "    html.Button('Predict', id='predict-button', n_clicks=0),\n",
    "    dcc.Graph(id='prediction-graph'),\n",
    "    html.Button('Load New Data', id='load-data-button', n_clicks=0)\n",
    "])\n",
    "\n",
    "# Callback to update the prediction\n",
    "@app.callback(\n",
    "    Output('prediction-graph', 'figure'),\n",
    "    Input('predict-button', 'n_clicks'),\n",
    "    Input('product_id', 'value')\n",
    ")\n",
    "def update_prediction(n_clicks, product_id):\n",
    "    if n_clicks > 0:\n",
    "        # Load the model and the scaler\n",
    "        with open('model.pkl', 'rb') as f:\n",
    "            model = pickle.load(f)\n",
    "        with open('scaler.pkl', 'rb') as f:\n",
    "            scaler = pickle.load(f)\n",
    "        \n",
    "        # Filter the data for the given product\n",
    "        product_data = data_grouped[data_grouped['product_id'] == product_id]\n",
    "\n",
    "        if product_data.empty:\n",
    "            return {\n",
    "                'data': [],\n",
    "                'layout': go.Layout(\n",
    "                    title='No data available for this product'\n",
    "                )\n",
    "            }\n",
    "\n",
    "        # Make predictions for each day of the week\n",
    "        predictions = []\n",
    "        for day in range(1, 8):\n",
    "            input_data = product_data[product_data['day'] == day][['price', 'day', 'week', 'month', 'year', 'cart', 'view', 'category_num']]\n",
    "            if input_data.empty:\n",
    "                predictions.append(0)\n",
    "            else:\n",
    "                input_data = scaler.transform(input_data)\n",
    "                prediction = model.predict(input_data)\n",
    "                predictions.append(prediction[0])\n",
    "\n",
    "        # Create the graph\n",
    "        figure = {\n",
    "            'data': [\n",
    "                go.Bar(\n",
    "                    x=list(range(1, 8)),\n",
    "                    y=predictions,\n",
    "                    name='Predicted Sales'\n",
    "                )\n",
    "            ],\n",
    "            'layout': go.Layout(\n",
    "                title=f'Sales Prediction for Product ID: {product_id}',\n",
    "                xaxis={'title': 'Day of the Week'},\n",
    "                yaxis={'title': 'Predicted Sales'}\n",
    "            )\n",
    "        }\n",
    "        return figure\n",
    "\n",
    "    return {\n",
    "        'data': [],\n",
    "        'layout': go.Layout(\n",
    "            title='Select a product ID and press \"Predict\"'\n",
    "        )\n",
    "    }\n",
    "\n",
    "# Callback to load and train the model with new data\n",
    "@app.callback(\n",
    "    Output('load-data-button', 'children'),\n",
    "    Input('load-data-button', 'n_clicks')\n",
    ")\n",
    "def load_new_data(n_clicks):\n",
    "    if n_clicks > 0:\n",
    "        # Load new data and combine it\n",
    "        new_data_path = 'forecasting_dataset_new.pkl'\n",
    "        new_data_grouped = load_and_prepare_data(new_data_path)\n",
    "        \n",
    "        global data_grouped\n",
    "        data_grouped = pd.concat([data_grouped, new_data_grouped]).drop_duplicates().reset_index(drop=True)\n",
    "        \n",
    "        # Retrain the model with the combined data\n",
    "        model, scaler = train_incremental_model(data_grouped, model, scaler)\n",
    "        \n",
    "        # Save the updated model and the scaler\n",
    "        with open('model.pkl', 'wb') as f:\n",
    "            pickle.dump(model, f)\n",
    "        with open('scaler.pkl', 'wb') as f:\n",
    "            pickle.dump(scaler, f)\n",
    "        \n",
    "        return 'New Data Loaded and Model Updated'\n",
    "    \n",
    "    return 'Load New Data'\n",
    "\n",
    "# Run the app\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=True, port=8065)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
